{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to satellite image dataset\n",
    "base_dir = '/kaggle/input/satellite-image-classification/data'\n",
    "\n",
    "# Set configuration parameters\n",
    "IMAGE_SIZE = (128, 128)  # Standard dimensions for neural network input\n",
    "BATCH_SIZE = 32         # Number of images per training batch\n",
    "EPOCHS = 20            # Number of complete passes through the dataset\n",
    "DATA_PATH = base_dir   # Root directory containing image folders\n",
    "\n",
    "# Initialize data generator with preprocessing options\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,     # Normalize pixel values to range [0,1]\n",
    "    validation_split=0.2    # Reserve 20% of data for validation\n",
    ")\n",
    "\n",
    "# Create training data generator\n",
    "train_data = datagen.flow_from_directory(\n",
    "    DATA_PATH,              # Source directory\n",
    "    target_size=IMAGE_SIZE, # Resize images\n",
    "    batch_size=BATCH_SIZE,  # Images per batch\n",
    "    class_mode='categorical', # Multi-class classification\n",
    "    subset='training'       # Use training split\n",
    ")\n",
    "\n",
    "# Create validation data generator with same parameters\n",
    "val_data = datagen.flow_from_directory(\n",
    "    DATA_PATH,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'     # Use validation split\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN architecture with increasing filters\n",
    "model = Sequential([\n",
    "    # First convolutional block - Initial feature extraction\n",
    "    Conv2D(16, (3, 3), activation='relu', input_shape=(*IMAGE_SIZE, 3)),  # 16 filters, 3x3 kernel\n",
    "    MaxPooling2D((2, 2)),  # Reduce spatial dimensions by half\n",
    "    \n",
    "    # Second convolutional block - Increased feature complexity\n",
    "    Conv2D(32, (3, 3), activation='relu'),  # 32 filters for more feature maps\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Third convolutional block - Deep feature extraction\n",
    "    Conv2D(64, (3, 3), activation='relu'),  # 64 filters for complex features\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Fourth convolutional block - Final feature extraction\n",
    "    Conv2D(128, (3, 3), activation='relu'),  # 128 filters for detailed features\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Flatten layer to convert 2D feature maps to 1D vector\n",
    "    Flatten(),\n",
    "    \n",
    "    # Dense layers for classification\n",
    "    Dense(128, activation='relu'),  # Fully connected layer\n",
    "    Dropout(0.5),  # Prevent overfitting by randomly dropping 50% of nodes\n",
    "    Dense(train_data.num_classes, activation='softmax')  # Output layer - one node per class\n",
    "])\n",
    "\n",
    "# Configure model training parameters\n",
    "model.compile(\n",
    "    optimizer='adam',               # Adam optimizer for adaptive learning\n",
    "    loss='categorical_crossentropy', # Loss function for multi-class classification\n",
    "    metrics=['accuracy']            # Track accuracy during training\n",
    ")\n",
    "\n",
    "# Display model architecture summary\n",
    "model.summary()\n",
    "\n",
    "# Train model on dataset\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=EPOCHS                   # Train for specified number of epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and preprocessing configuration\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,           # Normalize pixel values\n",
    "    validation_split=0.2,      # 20% validation split\n",
    "    rotation_range=30,         # Random rotation\n",
    "    width_shift_range=0.2,     # Horizontal shift\n",
    "    height_shift_range=0.2,    # Vertical shift\n",
    "    horizontal_flip=True,      # Flip images horizontally\n",
    "    zoom_range=0.2            # Random zoom\n",
    ")\n",
    "\n",
    "# Dataset configuration\n",
    "IMG_SIZE = (64, 64)\n",
    "data_dir = 'path'\n",
    "\n",
    "# Generate training data with augmentation\n",
    "train_data = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Generate validation data without augmentation\n",
    "val_data = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=1,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Calculate class weights to handle imbalanced data\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_data.classes),\n",
    "    y=train_data.classes\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Load pre-trained VGG16 model\n",
    "base_model = VGG16(\n",
    "    weights='imagenet', \n",
    "    include_top=False, \n",
    "    input_shape=(*IMG_SIZE, 3)\n",
    ")\n",
    "\n",
    "# Freeze base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(train_data.num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "transfer = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=15\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "val_loss, val_accuracy = model.evaluate(val_data)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Generate predictions and metrics\n",
    "val_predictions = model.predict(val_data)\n",
    "y_pred = val_predictions.argmax(axis=1)\n",
    "y_true = val_data.classes\n",
    "\n",
    "# Print classification metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, \n",
    "      target_names=list(val_data.class_indices.keys())))\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
