{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "CONFIG = {\n",
    "    'IMG_SIZE': (32, 32),\n",
    "    'BATCH_SIZE': 64,\n",
    "    'NUM_CLASSES': 43,\n",
    "    'EPOCHS': 50,\n",
    "    'LEARNING_RATE': 0.001,\n",
    "    'RANDOM_STATE': 42,\n",
    "    'TEST_SIZE': 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "def load_data(dataset_path):\n",
    "    df = pd.read_csv(os.path.join(dataset_path, \"Train.csv\"))\n",
    "    image_paths = [os.path.join(dataset_path, \"Train\", str(row['ClassId']), row['Path']) \n",
    "                  for _, row in df.iterrows()]\n",
    "    \n",
    "    # Load and preprocess images\n",
    "    images = [cv2.resize(cv2.imread(img_path), CONFIG['IMG_SIZE']) \n",
    "             for img_path in image_paths]\n",
    "    images = np.array(images) / 255.0\n",
    "    \n",
    "    return images, df[\"ClassId\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "def create_model():\n",
    "    model = keras.Sequential([\n",
    "        # First Conv Block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Second Conv Block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Third Conv Block\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Dense Layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(CONFIG['NUM_CLASSES'], activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=CONFIG['LEARNING_RATE']),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    ax1.plot(history.history['accuracy'], label='Training')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation')\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax2.plot(history.history['loss'], label='Training')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation')\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "DATASET_PATH = \"path_to_dataset\"\n",
    "images, labels = load_data(DATASET_PATH)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    images, labels, \n",
    "    test_size=CONFIG['TEST_SIZE'], \n",
    "    random_state=CONFIG['RANDOM_STATE']\n",
    ")\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=CONFIG['NUM_CLASSES'])\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=CONFIG['NUM_CLASSES'])\n",
    "\n",
    "# Create and compile model\n",
    "model = create_model()\n",
    "model.summary()\n",
    "\n",
    "# Define callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-7)\n",
    "]\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=CONFIG['BATCH_SIZE'],\n",
    "    epochs=CONFIG['EPOCHS'],validation_split=0.2,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
